# Der Workflow mit Transkribus

Am Anfang der Transkription stand die Anfertigung hochauflösender Digitalisate. Diese wurden uns vom [Wiener Stadt- und Landesarchiv](https://grundbuecher.acdh.oeaw.ac.at/) zur Verfügung gestellt. Wir bedanken uns herzlich bei Matthias Vigl und Christoph Sonnlechner. Gescannt wurden alle Seiten der vier zur Bearbeitung ausgewählten Kodizes, einzige Ausnahme sind Leerseiten jeweils am Anfang und am Ende der Handschriften.

Die Scans wurden anschließend mit der HTR-Plattform [Transkribus](https://www.transkribus.org/) bearbeitet, um das ca. 3500 Seiten umfassende Korpus semiautomatisch zu transkribieren. Die Entscheidung, Transkribus bei der Transkription der Grundbücher zu verwenden, fiel in der Konzeptionsphase des Projekts. Zwei Gründe waren dafür ausschlaggebend. Einerseits die Zeitersparnis gegenüber einer manuellen Transkription, andererseits die langfristige Nachnutzbarkeit der Ground Truth. Diese kann dazu genutzt werden, zeiteffizient automatische Transkriptionen auch für die Stadtbücher zu generieren, die im Projekt nicht berücksichtigt werden konnten. Dazu zählen etwa die Satzbücher, in welchen parallel zu den Grundbüchern Kreditgeschäfte dokumentiert wurden. 

Die noch ohne den Einsatz von HTR erstellte [Edition des Satzbuchs CD](https://grundbuecher.acdh.oeaw.ac.at/) diente als Grundlage für die Arbeit an den Grundbüchern. Zum Zeitpunkt der Antragstellung des Projekts war noch kein öffentliches Modell in Transkribus verfügbar, das zufriedenstellende Ergebnisse für die frühneuhochdeutschen Kanzleischriften der Grundbücher erbrachte. Daher wurde ein Seit aus 60 Seiten des Satzbuchs CD zusammengestellt, das die Ground Truth für ein eigenes Grundbuchmodell bildete. Bei ersten Tests stellte sich heraus, dass bestimmte Normalisierungen zwar eine wichtige Hilfestellung für den menschlichen Leser sind, beim Modell-Training aber zu schlechteren Ergebnissen führen können. Besonders betraf das die moderne Interpunktion und die damit einhergehende Groß- und Kleinschreibung. Daher wurde beschlossen, den Transkriptionstext anzupassen. Aus den hier gemachten Erfahrungen kristallisierten sich pragmatische [Transkriptionsrichtlinien für die Kauf- und Gewerbücher](transkriptionsrichtlinien.md) heraus. Nachdem diese Richtlinien auf die Ground Truth angewendet wurden, erreichte das Modell eine CER von unter 4% auf dem Validierungsset, was als Grundlage für die Grundbücher praktikabel schien.

Die Bearbeitung der Grundbücher erfolgte Buch für Buch in chronologischer Reihenfolge. Begonnen wurde mit dem Kaufbuch E, das die Jahre von 1420 bis einschließlich 1437 abdeckt. Vorbereitend für die HTR-Erkennung wurde das Layout des gesamten Dokuments zuerst mit der automatischen Layoutanalyse erfasst und anschließend nachbearbeitet. Neben den Fehlerkorrekturen wird hierbei eine Segmentierung vorgenommen. Foliierung, Rubrik- und Unterüberschriften sowie die einzelnen Einträge stellen jeweils eine Textregion dar. Die Lesereihenfolge der Einträge wurde so standardisiert, dass zuerst der Rechtsinhalt, dann die Gebühr und abschließend die Marginalien von links nach rechts wiedergegeben werden. Einschüben und Hinzufügungen wurden an der intendierten Stelle im Satz positioniert, indem die betreffenden Zeilen geteilt wurden. Sie sind damit als spätere Hinzufügungen zu erkennen, der Lesefluss wird aber nicht unterbrochen.

Nach der Segmentierung wurde das auf Basis des Satzbuchs CD trainierte Modell auf die ersten 25 Seiten des Kaufbuchs angewandt. Die Resultate blieben dabei vorerst hinter den Erwartungen zurück. Verantwortlich dafür waren nicht die unterschiedlichen Schreiberhände, sondern das ungleiche Vokabular. Die meisten Fehler traten aufgrund unbekannter Abkürzungen auf. Folglich gestaltete sich die Korrektur der Transkription zeitintensiver als erhofft. Eine deutliche Verbesserung stellte sich aber ein, nachdem ein neues Modell trainiert wurde, in das die neu gewonnene Ground Truth der korrigierten Seiten einfloss. Mit diesem Modell wurden die nächsten 25 Seiten transkribiert, dann kontrolliert und wiederum als Ground Truth für ein neues Modell verwendet. Dieses Modell, dessen CER bei nur noch bei knapp 2% auf einem händisch zusammengestellten Validierungsset lag, war funktional genug, um die restlichen 450 Seiten der Handschrift zu transkribieren. 

Eingesetzt wurde dieses Schneeballprinzip auch bei den Gewerbüchern C und D. Beim zeitgleich mit Kaufbuch E geführten Gewerbuch C wurden die ersten 50 Seiten mit einem Modell transkribiert, welches mit dem gesamten Kaufbuch E trainiert wurde. Damit entstand wiederum ein verbessertes Modell, das auf dem restlichen Gewerbuch zu guten Ergebnissen und damit einer schnelleren Korrektur führte. Auch hier war die Ergänzung der 50 Seiten hilfreich, da durch die andere Art der Rechtsgeschäfte im Gewerbuch dem Modell ein neuer Wortschatz „beigebracht“ werden mussten. Mit dem Modell, das nun mit den vollständigen Grundbüchern der Jahre 1420 bis 1437 trainiert war, konnte im selben Verfahren das Gewerbuch D (1438–1473) transkribiert werden. 

Besonders günstig für den Workflow erwies sich die alphabetische Rubrizierung des Kaufbuchs E und Gewerbuchs D. Da innerhalb einer Rubrik alle Hände repräsentiert sind, waren die Trainingsdaten aus den ersten 50 Seiten stets divers. Deshalb wurde der Ablauf beim rein chronologisch geführten Gewerbuch E (1474-1517) modifiziert. Es wurden nicht einfach die ersten 50 Seiten für das Training eines auf die Handschrift optimierten Modells genutzt, sondern Seiten aus Anfang, Mitte und Ende des Dokuments. Bei der Kontrolle stellte sich bald heraus, dass die Einträge ab ungefähr 1500 ein Spezialmodell erforderten. Ab diesem Zeitpunkt wechselten die Schreiber von der Bastarda zu einer frühen Kurrentschrift. Da diese sich von den älteren Schriftarten stark unterschied, wurde ein eigenes Modell mit einem händisch kuratierten Trainingsdatenset trainiert, dass die Arbeit erleichterte.

Während des Transkriptionsprozesses wurde stets ein komplett neues Modell trainiert, anstatt das vorherige als Base Model zu nutzen. Durch diese Entscheidung war die Möglichkeit gegeben, eventuelle Verbesserungen an bestehenden Transkriptionen mit ins Modell zu überführen. Zu Beginn wurde der _unclear_-Tag nämlich noch relativ häufig vergeben, um unsichere Lesungen vom Training auszuschließen. Oft waren es schwer leserliche Eigennamen oder stark abbreviierte Rechtsbegriffe, deren Auflösung sich erst durch die Lektüre anderer Einträge ergab. Beispielsweise wurde eine häufig wiederkehrende lateinische Notation anfänglich im falschen Tempus expandiert. Um Flüchtigkeitsfehlern bei der Textkontrolle entgegenzuwirken, wurde zudem bei der HTR-Erkennung kein Gebrauch von Language Models gemacht. Bei Tests mit Hinzuschaltung des Sprachmodells wurden einige unleserliche Wörter zwar besser erkannt, negativ viel jedoch die Tendenz auf, „false friends“ hervorzubringen. Wichen häufig vorkommende Wörter leicht in ihrer Schreibweise ab – etwa durch ein „u“ anstatt eines „w“ in „hausfraw“ – wurden sie trotzdem in der gängigsten Variante transkribiert. Zwar fällt diese Art von Ungenauigkeit im Kontext der Projektziele nicht ins Gewicht, für die Erstellung eines Modells zur Nachnutzung sollte die Ground Truth jedoch so fehlerfrei wie möglich sein.

Ein finales Grundbuchmodell wurde nach Abschluss der Transkription trainiert und als öffentliches Modell [in Transkribus verfügbar gemacht](https://readcoop.eu/model/viennese-property-registers-enhg-15th-16th-century/). Es umfasst 1.228.552 Wörter und weist eine Fehlerrate von etwa 1,5 Prozent auf. Bemessen ist diese an einem Validierungsset aus 70 ausgewählten Seiten, die das breite Spektrum der Hände und Schriftarten in den Grundbüchern widerspiegeln. Auf andere Quellen angewendet ist die reale Fehlerquote deutlich höher, da es sich um ein Spezialmodell handelt ist. Zwar besteht das Trainingsmaterial aus 3301 Seiten, die von wechselnden Händen beschrieben wurden, jedoch ist das Vokabular aufgrund der fomulaischen Sprache eingeschränkt. Ein Teil der Ground Truth ist allerdings in eine Testversion eines [generischen Modells für das 15. und 16. Jahrhundert](https://readcoop.eu/model/generic-model-15th-16th-century-german-prototype/]) eingeflossen. In Kooperation mit Angela Huang, Ruta Bruzevica, dem Stadtarchiv Stade und weiteren Partner:innen wurde dazu handschriftliches Material verschiedener Provenienz kombiniert. 
